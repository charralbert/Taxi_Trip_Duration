{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3072f81f-ad31-4009-ba33-10df39756e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m \n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as mp \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95647991-8358-4907-b257-024c828c5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read cleaned data from project_deliverable_1\n",
    "df=pd.read_csv(\"project_deliverable_1.csv\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e77f0-4407-46e6-b09a-b073f2e984a9",
   "metadata": {},
   "source": [
    "## 1. Baseline Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b269765-a641-4d8e-ad02-1a0b29da0ef2",
   "metadata": {},
   "source": [
    "The linear regression model was chosen as the baseline model because it is one of the simplest and most interpretable machine learning algorithms for regression tasks. It provides a clear mathematical relationship between the input features and the target variable, making it easy to understand how each factor influences trip duration. Additionally, it also has a low computational cost and helps identify whether the relationship in the data are linear or require non linear modeling approaches later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ec67a-6e9c-4c07-b84d-02329d17e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_mapping = {\n",
    "    'Monday': 0, 'Tuesday': 1, 'Wednesday': 2,'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
    "}\n",
    "df['pickup_day_num'] = df['pickup_day'].map(day_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0780a11-a190-46f6-af0b-49ac602c59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a simple, interpretable baseline model in scikit-learn\n",
    "features=['trip_distance_km','pickup_hour','pickup_day_num']\n",
    "target='trip_duration'\n",
    "\n",
    "X=df[features]\n",
    "y=df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9a9e6-b467-45fd-96ed-dc7fded4f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4a303-6291-4721-a42a-0d3be6d54fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "linreg=LinearRegression()\n",
    "linreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e780d8-37c5-4e53-b54a-098244cc38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print learned parameters\n",
    "print(\"Intercept(b0)\",linreg.intercept_)\n",
    "print(\"Coefficient for trip_distance_km(b1)\",linreg.coef_[0])\n",
    "print(\"Coefficient for pickup_hour(b2)\",linreg.coef_[1])\n",
    "print(\"Coefficient for pickup_day_num(b3)\",linreg.coef_[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd918b4-b680-40df-b3eb-2d06543280a4",
   "metadata": {},
   "source": [
    "After training the linear regression model, the following was gotten as the results for the parameters: an intercept of approximately 372.31, and three coefficients for our independent variable -131.64 for trip_distance_km, 4.05 for pickup_hour and -12.6 for pickup_day_num.\n",
    "\n",
    "The intercept represents the baseline predicted trip duration in seconds when all features are zero. \n",
    "\n",
    "The trip_distance_km means that for every additional km traveled, the trip duration increases by about 131.6 seconds(≈2.2 minutes), which aligns with expectations since longer distances take more time. \n",
    "\n",
    "The pickup_hour means that trips happening later in the day tend to last slightly longer, possibly due to traffic or rush hour timings. \n",
    "\n",
    "The pickup_day_num implies that as the week progresses, the average trip duration decreases by about 12.6 seconds per day, this may be due to lighter traffic as the weekend approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f32038-9156-417a-b366-ebefdea6e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict data\n",
    "y_pred=linreg.predict(X)\n",
    "\n",
    "#Calculate regression metrics\n",
    "mae=metrics.mean_absolute_error(y,y_pred)\n",
    "mse=metrics.mean_squared_error(y,y_pred)\n",
    "rmse=metrics.root_mean_squared_error(y,y_pred)\n",
    "r2=metrics.r2_score(y,y_pred)\n",
    "\n",
    "print(\"Mean absolute error (MAE):\",mae)\n",
    "print(\"Mean squared error (MSE):\",mse)\n",
    "print(\"Root mean squared error (RMSE):\",rmse)\n",
    "print(\"R-squared (R^2)\",r2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360e0a9-5a47-4abb-9a79-857782c215af",
   "metadata": {},
   "source": [
    "The model evaluated the MAE, MSE, RMSE, and R^2. The mean squared error are squared so this metric heavily penalizes large mistakes, and is sensitive to outliers (in this case unusually short or long trip durations). The relatively large MSE value observed here(≈172,080) might initially appear high, but this is expected since it is measured in seconds^2. \n",
    "\n",
    "To make the results easier to interpret, the RMSE was taken to convert it back to seconds. In this case, the RMSE is approximately 415 seconds (≈6.9 minutes), meaning that, on average, our model's predictions are off by about seven minutes. \n",
    "\n",
    "Meanwhile, the MAE of about 283 seconds (≈4.7 mins) provides a more direct measure of the typical prediction error without squaring, and the R^2 value of 0.59 indicates that around 59% of the variability in trip durations can be explained by our chosen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b813005-d0bb-4990-a101-916f6050586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report performance via train–validation splits\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, linreg.predict(X_train)))\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, linreg.predict(X_test)))\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd736770-9845-4582-8903-8fd2b0209e16",
   "metadata": {},
   "source": [
    "The linear regression model appears to generalize well based on the evaluation metrics. The reaining RMSE(415.4 seconds) and testing RMSE(412.53 seconds) are very close, which suggests that the model performs consistently on both seen and unseen data. This means that the model has a good balance between bias and variance. \n",
    "\n",
    "From a bias-variance trade-off perspective, the linear regression model has low varianace since its performance remains fairly stable accross datasets, and moderate bias because it simplifies trip duration prediction into a linear relationship. The model does not underfit or overfit, because it captures the main trend between trip duration, distance, and time features and also does not perform significantly worse on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7197e-e351-4b03-a5c2-a9ae2561e9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (taxi_env)",
   "language": "python",
   "name": "taxi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
